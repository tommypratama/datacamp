{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Concatenating data\n",
    "\n",
    "Anda akan belajar cara melakukan operasi gaya database untuk menggabungkan DataFrames. Secara khusus, Anda akan belajar tentang `appending` dan `concatenating` DataFrames sambil bekerja dengan berbagai dataset dunia nyata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending & concatenating Series\n",
    "\n",
    "### Appending pandas Series\n",
    "\n",
    "Dalam latihan ini, Anda akan memuat data penjualan dari bulan Januari, Februari, dan Maret ke dalam DataFrames. Kemudian, Anda akan mengekstrak Series dengan kolom `'Units'` dari masing-masing dan menambahkannya bersama dengan metode chaining menggunakan `.append()`.\n",
    "\n",
    "Untuk memastikan bahwa susunan berfungsi, Anda akan mencetak irisan (*slices*) dari Series ini, dan akhirnya, Anda akan menambahkan hasilnya untuk mengetahui total unit yang terjual pada kuartal pertama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n",
      "642\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load 'sales-jan-2015.csv' into a DataFrame: jan\n",
    "jan = pd.read_csv('datasets/sales/sales-jan-2015.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Load 'sales-feb-2015.csv' into a DataFrame: feb\n",
    "feb = pd.read_csv('datasets/sales/sales-feb-2015.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Load 'sales-mar-2015.csv' into a DataFrame: mar\n",
    "mar = pd.read_csv('datasets/sales/sales-mar-2015.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Extract the 'Units' column from jan: jan_units\n",
    "jan_units = jan['Units']\n",
    "\n",
    "# Extract the 'Units' column from feb: feb_units\n",
    "feb_units = feb['Units']\n",
    "\n",
    "# Extract the 'Units' column from mar: mar_units\n",
    "mar_units = mar['Units']\n",
    "\n",
    "# Append feb_units and then mar_units to jan_units: quarter1\n",
    "quarter1 = jan_units.append(feb_units).append(mar_units)\n",
    "\n",
    "# Print the first slice from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "\n",
    "# Print the second slice from quarter1\n",
    "print(quarter1.loc['feb 26, 2015':'mar 7, 2015'])\n",
    "\n",
    "# Compute & print total sales in quarter1\n",
    "print(quarter1.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Seperti yang Anda lihat, menambahkan `pandas` Series sangat mudah!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating pandas Series along row axis\n",
    "\n",
    "Setelah mempelajari cara menambahkan Series, kini Anda akan belajar cara mencapai hasil yang sama dengan menggabungkan Series. Anda akan terus bekerja dengan data penjualan yang Anda lihat sebelumnya. Kali ini, DataFrames `jan`, `feb`, and `mar` telah dimuat sebelumnya.\n",
    "\n",
    "Tugas Anda adalah menggunakan `pd.concat()` dengan list Series untuk mencapai hasil yang sama dengan yang Anda dapatkan dengan menghubungkan panggilan ke `.append()`.\n",
    "\n",
    "Anda mungkin bertanya-tanya tentang perbedaan antara metode `pd.concat()` dan pandas `.append()`. Salah satu cara untuk memikirkan perbedaannya adalah `.append()` adalah kasus spesifik dari gabungan, sedangkan `pd.concat()` memberi Anda lebih banyak fleksibilitas, seperti yang akan Anda lihat di latihan selanjutnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty list: units\n",
    "units = []\n",
    "\n",
    "# Build the list of Series\n",
    "for month in [jan, feb, mar]:\n",
    "    units.append(month['Units'])\n",
    "\n",
    "# Concatenate the list: quarter1\n",
    "quarter1 = pd.concat(units, axis='rows')\n",
    "\n",
    "# Print slices from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "print(quarter1.loc['feb 26, 2015':'mar 7, 2015'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Seperti dalam latihan ini, Anda dapat mencapai hasil yang sama dengan menambahkan dengan *appending by concatenating* sumbu baris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending & concatenating DataFrames\n",
    "\n",
    "### Appending DataFrames with ignore_index\n",
    "\n",
    "Dalam latihan ini, Anda akan menggunakan dataset [Kumpulan Nama Bayi](https://www.data.gov/developers/baby-names-dataset/) (dari data.gov) lagi. Kali ini, baik DataFrames `names_1981` dan `names_1881` dimuat tanpa menentukan kolom Indeks (jadi Indeks default untuk keduanya adalah RangeIndexes).\n",
    "\n",
    "Anda akan menggunakan metode DataFrame `.append()` untuk membuat DataFrame `combined_names`. Untuk membedakan baris dari dua DataFrames asli, Anda akan menambahkan kolom `'year'` untuk masing-masing tahun (1881 atau 1981 dalam kasus ini). Selain itu, Anda akan menentukan `ignore_index=True` sehingga nilai-nilai indeks tidak digunakan di sepanjang sumbu gabungan. Sumbu yang dihasilkan sebagai gantinya akan diberi label `0, 1, ..., n-1` yang berguna jika Anda menggabungkan objek di mana sumbu gabungan tidak memiliki informasi pengindeksan yang berarti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "names_1881 = pd.read_csv('datasets/baby-names/names1881.csv', names=['name', 'gender', 'count'])\n",
    "names_1981 = pd.read_csv('datasets/baby-names/names1981.csv', names=['name', 'gender', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19455, 4)\n",
      "(1935, 4)\n",
      "(21390, 4)\n",
      "         name gender  count  year\n",
      "1283   Morgan      M     23  1881\n",
      "2096   Morgan      F   1769  1981\n",
      "14390  Morgan      M    766  1981\n"
     ]
    }
   ],
   "source": [
    "# Add 'year' column to names_1881 and names_1981\n",
    "names_1881['year'] = 1881\n",
    "names_1981['year'] = 1981\n",
    "\n",
    "# Append names_1981 after names_1881 with ignore_index=True: combined_names\n",
    "combined_names = names_1881.append(names_1981, ignore_index=True)\n",
    "\n",
    "# Print shapes of names_1981, names_1881, and combined_names\n",
    "print(names_1981.shape)\n",
    "print(names_1881.shape)\n",
    "print(combined_names.shape)\n",
    "\n",
    "# Print all rows that contain the name 'Morgan'\n",
    "print(combined_names.loc[combined_names.name == 'Morgan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating pandas DataFrames along column axis\n",
    "\n",
    "Fungsi `pd.concat()` dapat menggabungkan DataFrames secara horizontal maupun vertikal (vertikal adalah default). Untuk membuat DataFrames stack secara horizontal, Anda harus menentukan keyword argument `axis=1` atau `axis='columns`.\n",
    "\n",
    "Dalam latihan ini, Anda akan menggunakan data cuaca dengan suhu harian maksimum dan rata-rata yang diambil sampel dengan laju yang berbeda (triwulanan versus bulanan). Anda akan menggabungkan baris keduanya dan melihat bahwa, di mana baris tidak ada dalam DataFrame, nilai null dimasukkan dalam DataFrame gabungan. Ini sesuai dengan *outer join* (yang akan Anda jelajahi lebih rinci dalam latihan selanjutnya).\n",
    "\n",
    "File `'quarterly_max_temp.csv'` dan `'Monthly_mean_temp.csv'` telah dimuat sebelumnya ke DataFrames `weather_max` dan `weather_mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "weather_max = pd.DataFrame({ 'Month' : ['Jan', 'Apr', 'Jul', 'Oct'], 'Max TemperatureF' : [68, 89, 91, 84] }).set_index('Month')\n",
    "weather_mean = pd.DataFrame({ 'Month' : ['Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep'], 'Mean TemperatureF' : [53.1, 70.0, 34.935483870967744, 28.714285714285715, 32.354838709677416, 72.87096774193549, 70.13333333333334, 35.0, 62.612903225806456, 39.8, 55.451612903225815, 63.76666666666666]}).set_index('Month')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Max TemperatureF  Mean TemperatureF\n",
      "Apr              89.0          53.100000\n",
      "Aug               NaN          70.000000\n",
      "Dec               NaN          34.935484\n",
      "Feb               NaN          28.714286\n",
      "Jan              68.0          32.354839\n",
      "Jul              91.0          72.870968\n",
      "Jun               NaN          70.133333\n",
      "Mar               NaN          35.000000\n",
      "May               NaN          62.612903\n",
      "Nov               NaN          39.800000\n",
      "Oct              84.0          55.451613\n",
      "Sep               NaN          63.766667\n"
     ]
    }
   ],
   "source": [
    "# Create a list of weather_max and weather_mean\n",
    "weather_list = [weather_max, weather_mean]\n",
    "\n",
    "# Concatenate weather_list horizontally\n",
    "weather = pd.concat(weather_list, axis=1, sort=True)\n",
    "\n",
    "# Print weather\n",
    "print(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Di sinilah Anda mulai melihat keuntungan dari menggabungkan (*concatenating*) daripada menambahkan (*appending*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading multiple files to build a DataFrame\n",
    "\n",
    "Sering kali nyaman untuk membangun DataFrame besar dengan mem-parsing banyak file sebagai DataFrame dan menggabungkan semuanya sekaligus. Anda akan melakukan ini di sini dengan tiga file, tetapi, pada prinsipnya, pendekatan ini dapat digunakan untuk menggabungkan data dari lusinan atau ratusan file.\n",
    "\n",
    "Di sini, Anda akan bekerja dengan DataFrames yang dikompilasi dari [The Guardian's Olympic medal dataset](https://www.theguardian.com/sport/datablog/2012/jun/25/olympic-medal-winner-list-data).\n",
    "\n",
    "List `medal_types` telah dimuat sebelumnya untuk Anda, yang berisi string `'bronze'`, `'silver'`, dan `'gold'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_types = ['bronze', 'silver', 'gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                bronze  silver    gold\n",
      "France           475.0   461.0     NaN\n",
      "Germany          454.0     NaN   407.0\n",
      "Italy              NaN   394.0   460.0\n",
      "Soviet Union     584.0   627.0   838.0\n",
      "United Kingdom   505.0   591.0   498.0\n",
      "United States   1052.0  1195.0  2088.0\n"
     ]
    }
   ],
   "source": [
    "#Initialize an empyy list: medals\n",
    "medals =[]\n",
    "\n",
    "for medal in medal_types:\n",
    "    # Create the file name: file_name\n",
    "    file_name = \"datasets/olympic/%s_top5.csv\" % medal\n",
    "    # Create list of column names: columns\n",
    "    columns = ['Country', medal]\n",
    "    # Read file_name into a DataFrame: medal_df\n",
    "    medal_df = pd.read_csv(file_name, header=0, index_col='Country', names=columns)\n",
    "    # Append medal_df to medals\n",
    "    medals.append(medal_df)\n",
    "\n",
    "# Concatenate medals horizontally: medals_df\n",
    "medals_df = pd.concat(medals, axis='columns', sort=True)\n",
    "\n",
    "# Print medals_df\n",
    "print(medals_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Mampu membangun DataFrames dari banyak file seperti ini bisa sangat berguna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation, keys, & MultiIndexes\n",
    "\n",
    "### Concatenating vertically to get MultiIndexed rows\n",
    "\n",
    "Ketika menumpuk urutan DataFrames secara vertikal, kadang-kadang diinginkan untuk membangun MultiIndex untuk menunjukkan DataFrame dari mana setiap baris berasal. Ini dapat dilakukan dengan menentukan parameter `keys` dalam panggilan ke `pd.concat()`, yang menghasilkan indeks hierarkis dengan label dari `keys` sebagai label indeks terluar. Jadi, Anda tidak perlu mengganti nama kolom setiap DataFrame saat Anda memuatnya. Sebaliknya, hanya kolom Indeks yang harus ditentukan.\n",
    "\n",
    "Dua list telah dimuat sebelumnya: list kosong yang disebut `medals`, dan `medal_types`, yang berisi string `'bronze'`, `'silver'`, dan `'gold'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Total\n",
      "       Country               \n",
      "bronze United States   1052.0\n",
      "       Soviet Union     584.0\n",
      "       United Kingdom   505.0\n",
      "       France           475.0\n",
      "       Germany          454.0\n",
      "silver United States   1195.0\n",
      "       Soviet Union     627.0\n",
      "       United Kingdom   591.0\n",
      "       France           461.0\n",
      "       Italy            394.0\n",
      "gold   United States   2088.0\n",
      "       Soviet Union     838.0\n",
      "       United Kingdom   498.0\n",
      "       Italy            460.0\n",
      "       Germany          407.0\n"
     ]
    }
   ],
   "source": [
    "medals = []\n",
    "\n",
    "for medal in medal_types:\n",
    "\n",
    "    file_name = \"datasets/olympic/%s_top5.csv\" % medal\n",
    "    \n",
    "    # Read file_name into a DataFrame: medal_df\n",
    "    medal_df = pd.read_csv(file_name, index_col='Country')\n",
    "    \n",
    "    # Append medal_df to medals\n",
    "    medals.append(medal_df)\n",
    "    \n",
    "# Concatenate medals: medals\n",
    "medals = pd.concat(medals, keys=['bronze', 'silver', 'gold'], sort=True)\n",
    "\n",
    "# Print medals in entirety\n",
    "print(medals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Perhatikan MultiIndex `medals`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing MultiIndexed DataFrames\n",
    "\n",
    "Anda diberikan dengan DataFrame MultiIndexed seperti yang dihasilkan pada akhir latihan sebelumnya. Tugas Anda adalah untuk mengurutkan DataFrame dan menggunakan `pd.IndexSlice` untuk mengekstraksi irisan tertentu. Lihat latihan ini dari [Memanipulasi DataFrames dengan pandas](https://campus.datacamp.com/courses/manipulating-dataframes-with-pandas/advanced-indexing?ex=10) untuk menyegarkan ingatan Anda tentang cara berurusan dengan MultiIndexed DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total    454.0\n",
      "Name: (bronze, Germany), dtype: float64\n",
      "                 Total\n",
      "Country               \n",
      "France           461.0\n",
      "Italy            394.0\n",
      "Soviet Union     627.0\n",
      "United Kingdom   591.0\n",
      "United States   1195.0\n",
      "                       Total\n",
      "       Country              \n",
      "bronze United Kingdom  505.0\n",
      "gold   United Kingdom  498.0\n",
      "silver United Kingdom  591.0\n"
     ]
    }
   ],
   "source": [
    "# Sort the entries of medals: medals_sorted\n",
    "medals_sorted = medals.sort_index(level=0)\n",
    "\n",
    "# Print the number of Bronze medals won by Germany\n",
    "print(medals_sorted.loc[('bronze','Germany')])\n",
    "\n",
    "# Print data about silver medals\n",
    "print(medals_sorted.loc['silver'])\n",
    "\n",
    "# Create alias for pd.IndexSlice: idx\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# Print all the data on medals won by the United Kingdom\n",
    "print(medals_sorted.loc[idx[:, 'United Kingdom'], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Sepertinya hanya Amerika Serikat dan Uni Soviet yang memenangkan lebih banyak medali perak daripada Inggris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating horizontally to get MultiIndexed columns\n",
    "\n",
    "Dimungkinkan juga untuk membuat DataFrame dengan kolom yang diindeks secara hierarkis. Untuk latihan ini, Anda akan mulai dengan tiga list DataFrames yang disebut `dataframes`. Ketiga DataFrame berisi kolom `'Company'`, `'Product'`, dan `'Units'` dengan kolom `'Date'` sebagai indeks yang berkaitan dengan transaksi penjualan selama bulan Februari, 2015. DataFrame pertama menggambarkan transaksi `perangkat keras`, yang kedua menjelaskan transaksi `Perangkat Lunak` , dan yang ketiga, transaksi `Layanan`.\n",
    "\n",
    "Tugas Anda adalah menyatukan DataFrames secara horizontal dan membuat MultiIndex pada kolom. Dari sana, Anda dapat merangkum DataFrame yang dihasilkan dan mengiris beberapa informasi darinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_types = ['Hardware', 'Software', 'Service']\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for sales in sales_types:\n",
    "\n",
    "    file_name = \"datasets/sales/feb-sales-%s.csv\" % sales\n",
    "    \n",
    "    # Read file_name into a DataFrame: medal_df\n",
    "    sales_df = pd.read_csv(file_name, parse_dates=True, index_col='Date')\n",
    "    \n",
    "    # Append medal_df to medals\n",
    "    dataframes.append(sales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20 entries, 2015-02-02 08:33:01 to 2015-02-26 08:58:51\n",
      "Data columns (total 9 columns):\n",
      "(Hardware, Company)    5 non-null object\n",
      "(Hardware, Product)    5 non-null object\n",
      "(Hardware, Units)      5 non-null float64\n",
      "(Software, Company)    9 non-null object\n",
      "(Software, Product)    9 non-null object\n",
      "(Software, Units)      9 non-null float64\n",
      "(Service, Company)     6 non-null object\n",
      "(Service, Product)     6 non-null object\n",
      "(Service, Units)       6 non-null float64\n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 1.6+ KB\n",
      "None\n",
      "                            Hardware         Software Service\n",
      "                             Company          Company Company\n",
      "Date                                                         \n",
      "2015-02-02 08:33:01              NaN            Hooli     NaN\n",
      "2015-02-02 20:54:49        Mediacore              NaN     NaN\n",
      "2015-02-03 14:14:18              NaN          Initech     NaN\n",
      "2015-02-04 15:36:29              NaN        Streeplex     NaN\n",
      "2015-02-04 21:52:45  Acme Coporation              NaN     NaN\n",
      "2015-02-05 01:53:06              NaN  Acme Coporation     NaN\n",
      "2015-02-05 22:05:03              NaN              NaN   Hooli\n",
      "2015-02-07 22:58:10  Acme Coporation              NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# Concatenate dataframes: february\n",
    "february = pd.concat(dataframes, keys=['Hardware', 'Software', 'Service'], axis=1, sort=True)\n",
    "\n",
    "# Print february.info()\n",
    "print(february.info())\n",
    "\n",
    "# Assign pd.IndexSlice: idx\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# Create the slice: slice_2_8\n",
    "slice_2_8 = february.loc['2015-02-02':'2015-02-08', idx[:, 'Company']]\n",
    "\n",
    "# Print slice_2_8\n",
    "print(slice_2_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Bekerja dengan MultiIndexes dan MultiIndexed kolom mungkin tampak rumit pada awalnya, tetapi dengan latihan, itu akan menjadi kebiasaan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating DataFrames from a dict\n",
    "\n",
    "Anda sekarang akan meninjau kembali data penjualan yang Anda kerjakan sebelumnya di bab ini. Tiga DataFrames `jan`, `feb`, dan `mar` telah dimuat sebelumnya untuk Anda. Tugas Anda adalah untuk menjumlahkan jumlah semua penjualan di atas kolom `'Company'` menjadi satu DataFrame. Anda akan melakukan ini dengan membuat dictionary dari DataFrames ini dan kemudian menggabungkannya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 'sales-jan-2015.csv' into a DataFrame: jan\n",
    "jan = pd.read_csv('datasets/sales/sales-jan-2015.csv')\n",
    "\n",
    "# Load 'sales-feb-2015.csv' into a DataFrame: feb\n",
    "feb = pd.read_csv('datasets/sales/sales-feb-2015.csv')\n",
    "\n",
    "# Load 'sales-mar-2015.csv' into a DataFrame: mar\n",
    "mar = pd.read_csv('datasets/sales/sales-mar-2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Units\n",
      "         Company               \n",
      "january  Acme Coporation     76\n",
      "         Hooli               70\n",
      "         Initech             37\n",
      "         Mediacore           15\n",
      "         Streeplex           50\n",
      "february Acme Coporation     34\n",
      "         Hooli               30\n",
      "         Initech             30\n",
      "         Mediacore           45\n",
      "         Streeplex           37\n",
      "march    Acme Coporation      5\n",
      "         Hooli               37\n",
      "         Initech             68\n",
      "         Mediacore           68\n",
      "         Streeplex           40\n",
      "                    Units\n",
      "         Company         \n",
      "january  Mediacore     15\n",
      "february Mediacore     45\n",
      "march    Mediacore     68\n"
     ]
    }
   ],
   "source": [
    "# Make the list of tuples: month_list\n",
    "month_list = [('january', jan), ('february', feb), ('march', mar)]\n",
    "\n",
    "# Create an empty dictionary: month_dict\n",
    "month_dict = {}\n",
    "\n",
    "for month_name, month_data in month_list:\n",
    "\n",
    "    # Group month_data: month_dict[month_name]\n",
    "    month_dict[month_name] = month_data.groupby('Company').sum()\n",
    "\n",
    "# Concatenate data in month_dict: sales\n",
    "sales = pd.concat(month_dict)\n",
    "\n",
    "# Print sales\n",
    "print(sales)\n",
    "\n",
    "# Print all sales by Mediacore\n",
    "idx = pd.IndexSlice\n",
    "print(sales.loc[idx[:, 'Mediacore'], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Sekarang setelah Anda menguasai dasar-dasar *concatenating* data Anda, sekarang saatnya untuk belajar tentang berbagai jenis *joins*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer & inner joins\n",
    "\n",
    "### Concatenating DataFrames with inner join\n",
    "\n",
    "Tugas Anda adalah menghitung *inner join*!. DataFrame yang digunakan dalam variabel `bronze`, `silver`, `gold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "bronze = pd.read_csv('datasets/olympic/Bronze.csv', nrows=5, usecols=['Country', 'Total'], index_col='Country')\n",
    "silver = pd.read_csv('datasets/olympic/Silver.csv', nrows=5, usecols=['Country', 'Total'], index_col='Country')\n",
    "gold = pd.read_csv('datasets/olympic/Gold.csv', nrows=5, usecols=['Country', 'Total'], index_col='Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                bronze  silver    gold\n",
      "                 Total   Total   Total\n",
      "Country                               \n",
      "United States   1052.0  1195.0  2088.0\n",
      "Soviet Union     584.0   627.0   838.0\n",
      "United Kingdom   505.0   591.0   498.0\n",
      "France           475.0   461.0   378.0\n",
      "Germany          454.0   350.0   407.0\n"
     ]
    }
   ],
   "source": [
    "# Create the list of DataFrames: medal_list\n",
    "medal_list = [bronze, silver, gold]\n",
    "\n",
    "# Concatenate medal_list horizontally using an inner join: medals\n",
    "medals = pd.concat(medal_list, keys=['bronze', 'silver', 'gold'], axis=1, join='inner')\n",
    "\n",
    "# Print medals\n",
    "print(medals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling & concatenating DataFrames with inner join\n",
    "\n",
    "Dalam latihan ini, Anda akan membandingkan pertumbuhan PDB 10-tahun (Produk Domestik Bruto) historis di AS dan di Tiongkok. Data untuk AS dimulai pada tahun 1947 dan dicatat setiap tiga bulan; sebaliknya, data untuk Tiongkok dimulai pada tahun 1961 dan dicatat setiap tahun.\n",
    "\n",
    "Anda harus menggunakan kombinasi resampling dan inner join untuk meluruskan label indeks. Anda akan memerlukan [offset alias](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases) yang sesuai untuk melakukan resampling, dan metode `.resample()` harus dirantai dengan semacam metode agregasi ( `.pct_change()` dan `.last()` dalam kasus ini).\n",
    "\n",
    "DataFrames `china` dan `us` telah dimuat sebelumnya. Coba lihat output dari `china.head()` dan `us.head()` di IPython Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "china = pd.read_csv('datasets/gdp/gdp_china_clean.csv', parse_dates=True, index_col='Year')\n",
    "us = pd.read_csv('datasets/gdp/gdp_usa_clean.csv', parse_dates=True, index_col='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               China        US\n",
      "Year                          \n",
      "1971-12-31  0.988860  1.052270\n",
      "1981-12-31  0.972048  1.750922\n",
      "1991-12-31  0.962528  0.912380\n",
      "2001-12-31  2.492511  0.704219\n",
      "2011-12-31  4.623958  0.475082\n",
      "2021-12-31  3.789936  0.361780\n"
     ]
    }
   ],
   "source": [
    "# Resample and tidy china: china_annual\n",
    "china_annual = china.resample('A').last().pct_change(10).dropna()\n",
    "\n",
    "# Resample and tidy us: us_annual\n",
    "us_annual = us.resample('A').last().pct_change(10).dropna()\n",
    "\n",
    "# Concatenate china_annual and us_annual: gdp\n",
    "gdp = pd.concat([china_annual, us_annual], join='inner', axis=1)\n",
    "\n",
    "# Resample gdp and print\n",
    "print(gdp.resample('10A').last())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Sepertinya pertumbuhan PDB 10 tahun Tiongkok lebih tinggi daripada AS sejak 1990-an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
